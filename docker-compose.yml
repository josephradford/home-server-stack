version: '3.8'

services:
  adguard:
    image: adguard/adguardhome:latest
    container_name: adguard-home
    restart: unless-stopped
    ports:
      - "${SERVER_IP}:53:53/tcp"
      - "${SERVER_IP}:53:53/udp"
      - "${SERVER_IP}:3000:3000/tcp"
      - "${SERVER_IP}:80:80/tcp"
    volumes:
      - ./data/adguard/work:/opt/adguardhome/work
      - ./data/adguard/conf:/opt/adguardhome/conf
    networks:
      - homeserver

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    restart: unless-stopped
    ports:
      - "${SERVER_IP}:5678:5678"
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - N8N_HOST=${SERVER_IP}
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=http://${SERVER_IP}:5678/
      - GENERIC_TIMEZONE=${TIMEZONE}
    volumes:
      - ./data/n8n:/home/node/.n8n
    networks:
      - homeserver
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: unless-stopped
    ports:
      - "${SERVER_IP}:11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ./data/ollama:/root/.ollama
    networks:
      - homeserver

  ollama-setup:
    image: ollama/ollama:latest
    container_name: ollama-setup
    restart: "no"
    depends_on:
      - ollama
    volumes:
      - ./scripts:/scripts
    networks:
      - homeserver
    command: >
      sh -c "
        echo 'Waiting for Ollama to be ready...' &&
        sleep 10 &&
        echo 'Pulling coding model: deepseek-coder-v2...' &&
        ollama --host ollama:11434 pull deepseek-coder-v2 &&
        echo 'Pulling chat model: llama3.1:8b...' &&
        ollama --host ollama:11434 pull llama3.1:8b &&
        echo 'Models installed successfully!'
      "

networks:
  homeserver:
    driver: bridge